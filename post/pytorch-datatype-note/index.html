<!DOCTYPE html>
<html lang="en" dir="ltr" class="scroll-smooth" data-default-appearance="light"
  data-auto-appearance="true"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Notes on PyTorch Tensor Data Types &middot; Blowfish</title>
  <meta name="title" content="Notes on PyTorch Tensor Data Types &middot; Blowfish" />
  
  
  <meta name="keywords" content="PyTorch, " />
  
  
  <link rel="canonical" href="//localhost:1313/post/pytorch-datatype-note/" />
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.efe989cd11095eee5e026173915472c128b61ba8a106c22ead46741ec9255e7625dba193c53b8bb6fa5ea365248d4750e345dd71654234bdb04eadc42de91f30.css"
    integrity="sha512-7&#43;mJzREJXu5eAmFzkVRywSi2G6ihBsIurUZ0HsklXnYl26GTxTuLtvpeo2UkjUdQ40XdcWVCNL2wTq3ELekfMA==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.5200170cb3ed0adabce28870bf7ff061203bbefb075c90b7b76cc561cd376288fbd116092bd2e65b027908506b03f8fd15b5613608229bdc92f93ecf6d8faa64.js"
    integrity="sha512-UgAXDLPtCtq84ohwv3/wYSA7vvsHXJC3t2zFYc03Yoj70RYJK9LmWwJ5CFBrA/j9FbVhNggim9yS&#43;T7PbY&#43;qZA==" data-copy="" data-copied=""></script>
  
  
  <script src="/js/zoom.min.js"></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  <meta property="og:title" content="Notes on PyTorch Tensor Data Types" />
<meta property="og:description" content="In PyTorch,

    Tensor is the
primary object that we deal with (Variable is just a thin wrapper class for
Tensor). In this post, I will give a summary of pitfalls that we should avoid
when using Tensors. Since FloatTensor and LongTensor are the most popular
Tensor types in PyTorch, I will focus on these two data types." />
<meta property="og:type" content="article" />
<meta property="og:url" content="//localhost:1313/post/pytorch-datatype-note/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2017-11-15T21:22:45+08:00" />
<meta property="article:modified_time" content="2017-11-15T21:22:45+08:00" />


  <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Notes on PyTorch Tensor Data Types"/>
<meta name="twitter:description" content="In PyTorch,

    Tensor is the
primary object that we deal with (Variable is just a thin wrapper class for
Tensor). In this post, I will give a summary of pitfalls that we should avoid
when using Tensors. Since FloatTensor and LongTensor are the most popular
Tensor types in PyTorch, I will focus on these two data types."/>

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Notes on PyTorch Tensor Data Types",
    "headline": "Notes on PyTorch Tensor Data Types",
    
    "abstract": "\u003cp\u003eIn PyTorch,\n\u003ca href=\u0022http:\/\/pytorch.org\/docs\/master\/tensors.html#torch-tensor\u0022   target=\u0022_blank\u0022\u003e\n    \u003ccode\u003eTensor\u003c\/code\u003e\u003c\/a\u003e is the\nprimary object that we deal with (\u003ccode\u003eVariable\u003c\/code\u003e is just a thin wrapper class for\n\u003ccode\u003eTensor\u003c\/code\u003e). In this post, I will give a summary of pitfalls that we should avoid\nwhen using Tensors. Since \u003ccode\u003eFloatTensor\u003c\/code\u003e and \u003ccode\u003eLongTensor\u003c\/code\u003e are the most popular\n\u003ccode\u003eTensor\u003c\/code\u003e types in PyTorch, I will focus on these two data types.\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "\/\/localhost:1313\/post\/pytorch-datatype-note\/",
    "author" : {
      "@type": "Person",
      "name": ""
    },
    "copyrightYear": "2017",
    "dateCreated": "2017-11-15T21:22:45\u002b08:00",
    "datePublished": "2017-11-15T21:22:45\u002b08:00",
    
    "dateModified": "2017-11-15T21:22:45\u002b08:00",
    
    "keywords": ["PyTorch"],
    
    "mainEntityOfPage": "true",
    "wordCount": "756"
  }]
  </script>


  
  
  
  
  

<script src="/lib/jquery/jquery.slim.min.js" integrity=""></script>





















  
  

  
  
  <meta name="theme-color"/>
  
  
</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900">Blowfish</a>
            

        </nav>
        <nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12">

            
            
            
  <a href="/about/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="About">
        About
    </p>
</a>


            
            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            
            <div
                class="ltr:mr-14 rtl:ml-14 flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center space-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400" style="margin-right:5px">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" for="menu-controller" class="block">
            <input type="checkbox" id="menu-controller" class="hidden" />
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li>
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                    
  <li class="mt-1">
    <a href="/about/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="About">
            About
        </p>
    </a>
</li>



                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>





  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<article>
  

  <header id="single_header" class="mt-5 max-w-prose">
    
    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      Notes on PyTorch Tensor Data Types
    </h1>
    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  







  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2017-11-15 21:22:45 &#43;0800 &#43;0800">15 November 2017</time><span class="px-2 text-primary-500">&middot;</span><span>756 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">4 mins</span>
  

  
  
</div>







    </div>

    
    
    
    
    

    
      
      
<div class="flex author">
  
  <div class="place-self-center">
    
    
    <div class="text-2xl sm:text-lg">
</div>
  </div>
</div>
    

    

    

    
    <div class="mb-5"></div>
    
  
  </header>
  
  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
    

      <div class="min-w-0 min-h-0 max-w-fit">
        
        


        <div class="article-content max-w-prose mb-20">
          <p>In PyTorch,
<a href="http://pytorch.org/docs/master/tensors.html#torch-tensor"   target="_blank">
    <code>Tensor</code></a> is the
primary object that we deal with (<code>Variable</code> is just a thin wrapper class for
<code>Tensor</code>). In this post, I will give a summary of pitfalls that we should avoid
when using Tensors. Since <code>FloatTensor</code> and <code>LongTensor</code> are the most popular
<code>Tensor</code> types in PyTorch, I will focus on these two data types.</p>
<h1 class="relative group">Tensor operations 
    <div id="tensor-operations" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#tensor-operations" aria-label="Anchor">#</a>
    </span>        
    
</h1>


<h2 class="relative group">Tensor and Tensor operation 
    <div id="tensor-and-tensor-operation" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#tensor-and-tensor-operation" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>For operations between Tensors, the rule is strict. Both Tensors of the
operation must have the same data type, or you will see error messages like</p>
<pre tabindex="0"><code>TypeError: sub received an invalid combination of arguments - got (float), but expected one of:
 * (int value)
      didn&#39;t match because some of the arguments have invalid types: (!float!)
 * (torch.LongTensor other)
      didn&#39;t match because some of the arguments have invalid types: (!float!)
 * (int value, torch.LongTensor other)
</code></pre><p>As another example, several loss functions like
<a href="http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss"   target="_blank">
    <code>CrossEntropyLoss</code></a>
require that the target should be torch <code>LongTensor</code>. So before doing
operations, make sure that your input <code>Tensor</code> types match the function
definitions.</p>
<p>It is easy to convert the type of one <code>Tensor</code> to another <code>Tensor</code>. Suppose <code>x</code>
and <code>y</code> are <code>Tensor</code> of different types. You can use <code>x.type(y.type())</code> or
<code>x.type_as(y)</code> to convert <code>x</code> to the type of <code>y</code>.</p>


<h2 class="relative group">Tensor and scalar operation 
    <div id="tensor-and-scalar-operation" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#tensor-and-scalar-operation" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>For <code>FloatTensor</code>, you can do math operations (multiplication, addition,
division etc.) with a scalar of type <code>int</code> or <code>float</code>. But for <code>LongTensor</code>,
you can only do math operation with <code>int</code> scalar <strong>but not <code>float</code></strong>.</p>


<h1 class="relative group">Why do some losses require target to be LongTensor? 
    <div id="why-do-some-losses-require-target-to-be-longtensor" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#why-do-some-losses-require-target-to-be-longtensor" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p><a href="https://discuss.pytorch.org/t/problems-with-target-arrays-of-int-int32-types-in-loss-functions/140/3?u=jdhao"   target="_blank">
    According to PyTorch
developers</a>,
some use cases requires that the target be <code>LongTensor</code> type and int just can
not hold the target value.</p>


<h1 class="relative group">FloatTensor or DoubleTensor 
    <div id="floattensor-or-doubletensor" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#floattensor-or-doubletensor" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>For deep learning, precision is not a very important issue. Plus, GPU can not
process double precision very well. So <code>FloatTensor</code> is enough, which is also
the default type for model parameters.</p>


<h1 class="relative group">NumPy array and torch Tensor 
    <div id="numpy-array-and-torch-tensor" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#numpy-array-and-torch-tensor" aria-label="Anchor">#</a>
    </span>        
    
</h1>


<h2 class="relative group">Shared memory or not? 
    <div id="shared-memory-or-not" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#shared-memory-or-not" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>You can use <code>torch.from_numpy()</code> method to convert a NumPy array to
corresponding torch <code>Tensor</code>, which will share underlying memory with NumPy
array. To convert <code>Tensor</code> <code>x</code> to NumPy array, use <code>x.numpy()</code> to convert it to
a NumPy array, which also shares the memory with original <code>Tensor</code>.</p>
<p>Does torch <code>Tensor</code> and Numpy array always share the underlying memory? The
short answer is no. If their underlying data type is not compatible, a copy of
original data will be made. For example, if you try to save torch <code>FloatTensor</code>
as numpy array of type <code>np.float64</code>, it will trigger a deep copy.</p>


<h2 class="relative group">Correpsondece between NumPy and torch data type 
    <div id="correpsondece-between-numpy-and-torch-data-type" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#correpsondece-between-numpy-and-torch-data-type" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>It should be noted that not all NumPy arrays can be converted to torch
<code>Tensor</code>. Below is a table showing NumPy data types which is convertable to
torch <code>Tensor</code> type.</p>
<table>
<thead>
<tr>
<th>NumPy data type</th>
<th>Tensor data type</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>numpy.uint8</code></td>
<td><code>torch.ByteTensor</code></td>
</tr>
<tr>
<td><code>numpy.int16</code></td>
<td><code>torch.ShortTensor</code></td>
</tr>
<tr>
<td><code>numpy.int32</code></td>
<td><code>torch.IntTensor</code></td>
</tr>
<tr>
<td><code>numpy.int</code></td>
<td><code>torch.LongTensor</code></td>
</tr>
<tr>
<td><code>numpy.int64</code></td>
<td><code>torch.LongTensor</code></td>
</tr>
<tr>
<td><code>numpy.float32</code></td>
<td><code>torch.FloatTensor</code></td>
</tr>
<tr>
<td><code>numpy.float</code></td>
<td><code>torch.DoubleTensor</code></td>
</tr>
<tr>
<td><code>numpy.float64</code></td>
<td><code>torch.DoubleTensor</code></td>
</tr>
</tbody>
</table>


<h2 class="relative group">Speed comparison between NumPy and torch operations 
    <div id="speed-comparison-between-numpy-and-torch-operations" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#speed-comparison-between-numpy-and-torch-operations" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>I am curious to know the speed difference between torch Tensor operation and
equivalent NumPy ndarray operations. I do it in Jupyter-console using the
built-in magic <code>%timeit</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># torch Tensor on CPU</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="o">%</span><span class="n">timeit</span> <span class="n">z</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># torch Tensor on GPU</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="o">%</span><span class="n">timeit</span> <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># numpy ndarray on CPU</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="o">%</span><span class="n">timeit</span> <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></div><p>The result is listed on the following table:</p>
<table>
<thead>
<tr>
<th>Data type and device</th>
<th>Average operation time</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tensor on CPU</td>
<td>938 $\mu s$</td>
</tr>
<tr>
<td>Tensor on GPU</td>
<td>38.9 $\mu s$</td>
</tr>
<tr>
<td>NumPy ndarray (on CPU)</td>
<td>623 $\mu s$</td>
</tr>
</tbody>
</table>
<p>It is pretty clear that Tensor operations on GPU runs orders of magnitute
faster than operations on CPU. NumPy, due to its excellent implementation of
its core in C, runs a little bit faster than Tensor on CPU.</p>


<h1 class="relative group">Convert scalar to torch Tensor 
    <div id="convert-scalar-to-torch-tensor" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#convert-scalar-to-torch-tensor" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>You can convert a scalar to <code>Tensor</code> by providing the scalr to the <code>Tensor</code>
constructor, which will not achieve what you want. For
example,<code>torch.Tensor(1)</code> will not give you a <code>Tensor</code> which contains float 1.
Instead, the produced <code>Tensor</code> is something like</p>
<blockquote>
<p>1.00000e-20 *
5.4514
[torch.FloatTensor of size 1]</p>
</blockquote>
<p>To achieve what you want, you have to provide a list with single element 1 to
the <code>Tensor</code> constructor.</p>


<h1 class="relative group">References 
    <div id="references" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#references" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<ul>
<li><a href="https://github.com/pytorch/pytorch/issues/845"   target="_blank">
    Integer type Tensor only works with integer, but float type Tensor works both with integer and float</a>.</li>
<li><a href="https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381"   target="_blank">
    Tensor types must match</a>.</li>
<li><a href="https://discuss.pytorch.org/t/problems-with-target-arrays-of-int-int32-types-in-loss-functions/140/3"   target="_blank">
    Some loss functions require target to be LongTensor</a>.</li>
<li><a href="https://github.com/pytorch/pytorch/issues/2246"   target="_blank">
    NumPy and torch Tensor conversion, shared memory or not?</a></li>
</ul>
        </div>
                
        

        

          
      </div>
     
    
     <script>
        var oid = "views_post\/pytorch-datatype-note.md"
        var oid_likes = "likes_post\/pytorch-datatype-note.md"
      </script>
      
      
      
      <script type="text/javascript" src="/js/page.min.5b1bad196a6075a1e11bae1dc95f24f67b610948a00525e347566c5a62338ea78f1c7224ab9a53873dcdb2a1a7d7d391b8a8ef45561297f68806c01315b0c4f6.js" integrity="sha512-WxutGWpgdaHhG64dyV8k9nthCUigBSXjR1ZsWmIzjqePHHIkq5pThz3NsqGn19ORuKjvRVYSl/aIBsATFbDE9g=="></script>
  
    </section>
  <footer class="pt-8 max-w-prose print:hidden">

    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/post/pytorch-computation-graph/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Understanding Computational Graphs in PyTorch</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2017-11-12 13:22:46 &#43;0800 &#43;0800">12 November 2017</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="flex text-right group ml-3" href="/post/matplotlib-plotting-notes/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Matplotlib Plotting Notes -- Series 1</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2017-11-16 21:41:00 &#43;0800 &#43;0800">16 November 2017</time>
                  
                </span>
              </span>
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


    
  </footer>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">

    
    
    <p class="text-sm text-neutral-500 dark:text-neutral-400">
      &copy;
      2024
      
    </p>
    

    
    
    <p class="text-xs text-neutral-500 dark:text-neutral-400">
      
      
      Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a>
    </p>
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/js/process.min.62060bb247f4de2b6dde45903668fefb68d792f365587605177b1227c0cf43588701edaca0cb40e2c8e2789bd5ce67c1d2a215b9fb258c3496a7cd25e7cb5fdf.js" integrity="sha512-YgYLskf03itt3kWQNmj&#43;&#43;2jXkvNlWHYFF3sSJ8DPQ1iHAe2soMtA4sjieJvVzmfB0qIVufsljDSWp80l58tf3w=="></script>
  
  
</footer><div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="//localhost:1313/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

</html>
